#--- #############################################################
#--- title: "RICT IV WHPT SPR,AUT ONLY Classification  version 2"#
#--- output: html_document                                       #
#--- Author: Dr K. M Muyeba aka Maybin                           #
#--- December 9, 2019                                            #
#--- #############################################################

# ###############################################################################################
# This R Script, RICT_GB_SprAutOnlyClassification.Rmd, coded in RSTUDIO is a classification     #
# engine for WHPT in RICT IV.It incorporates NTAXA an ASPT for Spring, autumn This Script reads #
# all input features for the RICT model to predict WHPT index. Works with Classification v1.    #
# All data validation and transformation (conversion) are done in this script using functions   #
# predefined in HelperFunctionsv1.R                                                             # 
# ############################################################################################### 
 
 

```{r}

start_time <- Sys.time()
 

library(dplyr)

# incluce all classification functions 
path <- "C:/DEFRA/Phase2/RICT-GB-SingleYearSummerOnly_RSTUDIO_codes"


source(paste0(path,"/ClassificationfunctionsV2.R"))

set.seed (1234) #(2345)

# **** DEAL wiTH ALL INPUTS *****

# Input all predictions

Allpredictions <- read.csv("C:/DEFRA/Phase2/RICT-GB-SingleYearSprAutOnly_RSTUDIO_codes/Results/FinalPredictions_GB_data_sprAut_singleYear.csv")

# Input Adjustment factors for reference site quality scores (Q1, Q2, Q3, Q4, Q5)
GB685_Ass_score <- read.csv(paste0(path,"/EndGrp_AssessScores.csv"), header = TRUE)
# Input Multiplicative Adjustment factors Aj, 1,..,5)
Aj <- as.matrix(read.csv(paste0(path,"/adjustParams_ntaxa_aspt.csv"), header = TRUE))

 # Remove the raw_data log inputs, including the counting column 1
Allpredictions <- Allpredictions[,-c(1,3:15)] 

# Choose all classification biological variables
namesBiological <-    c("SPR_SEASON_ID", "SPR_TL2_WHPT_ASPT..ABW.DISTFAM.","SPR_TL2_WHPT_NTAXA..ABW.DISTFAM.", "SPR_NTAXA_BIAS", "SUM_SEASON_ID", "SUM_NTAXA_BIAS", "AUT_SEASON_ID", "AUT_TL2_WHPT_ASPT..ABW.DISTFAM.","AUT_TL2_WHPT_NTAXA..ABW.DISTFAM.","AUT_NTAXA_BIAS")
# NEXT !!!!
biologicalData <- Allpredictions[,  namesBiological] # c(56:67)] # change AZURE 

#Keep YEAR, WATERBODY
year_waterBody <- Allpredictions[,c("YEAR","WATERBODY")]
#Keep Allpredictions data only 
#Allpredictions <- Allpredictions[,c(1:55)] # Change AZURE

# Extract Ubias8 from Biological data # 
UBIAS_main <- biologicalData[,"SPR_NTAXA_BIAS"][1] # Put new AZURE. Use the default as 1.68

 # Put the UBIAS_main default value of 1.68 if the user does not enter any value or entersa -9
if(is.na(UBIAS_main) | UBIAS_main==-9) { # For NI model, the default is ZERO
  UBIAS_main <- 1.68
}

# OBSERVED NTAXA
Obs_ntaxa_spr    <- biologicalData[,"SPR_TL2_WHPT_NTAXA..ABW.DISTFAM."] # change AZURE
#Obs_ntaxa_aut   <- observed_ntaxa[,2]
Obs_ntaxa_aut    <- biologicalData[,"AUT_TL2_WHPT_NTAXA..ABW.DISTFAM."] # change AZURE

# OBSERVED ASPT
 Obs_aspt_spr   <- biologicalData[,"SPR_TL2_WHPT_ASPT..ABW.DISTFAM."] # change AZURE
# Obs_aspt_aut <- observed_aspt[,2]
Obs_aspt_aut   <- biologicalData[,"AUT_TL2_WHPT_ASPT..ABW.DISTFAM."] # change AZURE

# Keep all predictions data
#Allpredictions <- Allpredictions[,c(1:55)] # change AZURE

#Remove the "_CompFarm_" columns
Allpredictions <- select(Allpredictions, -matches("_CompFam_") ) # use the "-" with "match" from dplyr

# Also remove biological data, # Put AZURE 
                   
Allpredictions <- Allpredictions[,!names(Allpredictions) %in% namesBiological  ]

#Store allProbabilities in one dataframe. Use p1,p2,... etc in case data column positions change in future

probNames <- c("p1","p2","p3","p4","p5","p6","p7","p8","p9","p10","p11","p12","p13","p14","p15","p16","p17","p18","p19","p20","p21","p22","p23","p24","p25","p26","p27","p28","p29","p30","p31","p32","p33","p34","p35","p36","p37","p38","p39","p40","p41","p42","p43")

allProbabilities <-Allpredictions[,probNames]


```

## Calculate AdjustedExpected from all probabilities, WE4.5 of WFD72C

```{r}
# Compute Qij
Qij <- computeScoreProportions(GB685_Ass_score[,-1]) # Remove the first Column

# Compute Rj = sum(Pi*Qij)
Rj <- as.matrix(getWeighted_proportion_Rj(allProbabilities, Qij))# We should havew five of these 

#Multiply Rj by Aj, note each row of Aj is for NTAXA, ASPT, so transpose to multiply by Rj
RjAj <- compute_RjAj(Rj, Aj)
One_over_RjAj <- 1/RjAj
# 
# writeToFile(One_over_RjAj, path, "/1_over_RjAj.csv")
 
# Write a function that computes aspt, ntaxa adjusted (1 = "NTAXA", 2="ASPT") or select them by name as declared in the classification functions 
ntaxa_Adjusted <- select(Allpredictions, matches("_NTAXA_")) / RjAj[,"NTAXA"]
aspt_Adjusted  <- select(Allpredictions, matches("_ASPT_")) / RjAj[,"ASPT"] #Compute AdjExpected as E=Allpredictions/Sum(Rj*Aj)

Adjusted_Expected <- cbind(ntaxa_Adjusted, aspt_Adjusted)
Adjusted_Expected_new <- cbind(as.data.frame(Allpredictions[,1]), Adjusted_Expected) # Include site names from Allpredictions
writeToFile(Adjusted_Expected_new, path, "/AdjExpectedValues_new_data.csv")


# NOTE: Use "Allpredictions" or "AdjustedExpected_new" dataframes for the next section of calculations
```

# Calculation of Exp_ref from "AdjustedExpected_new" values, divide by K ( = 1.0049 for NTAXA,  = 0.9921 for ASPT)

```{r}

# ******* FOR ASPT ************
Exp_ref_aspt  <- aspt_Adjusted/0.9921
 
Ubias8 <- UBIAS_main
# run simulations from here 
N_runs <- 10000 # 10000

# find the non-bias corrected  EQR = Obs/ExpRef
nonBiasCorrected_WHPT_aspt_spr <- Obs_aspt_spr/select(Exp_ref_aspt, matches("_spr"))
nonBiasCorrected_WHPT_aspt_aut <- Obs_aspt_aut/select(Exp_ref_aspt, matches("_aut"))

# Now do the Obs_rb with ONE SITE Obs_aspt_spr[1]
sdobs_aspt <- SDObs_One_year_new(0.269, 0.279, 1)
   
SiteProbabilityclasses_spr_aspt <- data.frame() # Store site probabilities in a dataframe
SiteProbabilityclasses_aut_aspt <- data.frame() # Store site probabilities in a dataframe
SiteProbabilityclasses_spr_aut_comb_aspt <- data.frame()

EQRAverages_aspt_spr <- data.frame() # Store average EQRs for spr in a dataframe
EQRAverages_aspt_aut <- data.frame() # Store average EQRs for spr in a dataframe



# ******** FOr NTAXA ***************
Exp_ref_ntaxa <- ntaxa_Adjusted/1.0049 # select(Adjusted_Expected_new, matches("_NTAXA_"))/1.0049


# find the non-bias corrected  EQR = Obs/ExpRef, from the raw inputs, not used but useful for output checking purposes only
nonBiasCorrected_WHPT_ntaxa_spr <- Obs_ntaxa_spr/select(Exp_ref_ntaxa, matches("_spr"))
nonBiasCorrected_WHPT_ntaxa_aut <- Obs_ntaxa_aut/select(Exp_ref_ntaxa, matches("_aut"))

# Now do the Obs_rb with ONE SITE Obs_ntaxa_spr[1]
sdobs_ntaxa <- SDObs_One_year_new(0.247, 0.211, 1)
 

SiteProbabilityclasses_spr_ntaxa <- data.frame() # Store site probabilities in a dataframe
SiteProbabilityclasses_aut_ntaxa <- data.frame() # Store site probabilities in a dataframe
SiteProbabilityclasses_spr_aut_comb_ntaxa <- data.frame()
SiteMINTA_whpt_spr <- data.frame()
SiteMINTA_whpt_aut <- data.frame()
SiteMINTA_whpt_spr_aut <- data.frame()

EQRAverages_ntaxa_spr <- data.frame() # Store average EQRs for spr in a dataframe
EQRAverages_ntaxa_aut <- data.frame() # Store average EQRs for spr in a dataframe

Ubias8r_spr <-  getUbias8r_new (N_runs, Ubias8)
Ubias8r_aut <-  getUbias8r_new (N_runs, Ubias8)
  
for (k in 1:nrow(Allpredictions)) {
    #for (k in 1:5) {
    # LOOP all the sites from here   
    # Part 1. Adjust the Observed values
    # Loop starts from here with site = k, i.e. sqr (sqrt(Obs) + ZObs) + Ubias8r
  
  # Deal with NTAXA
  ObsIDX8r_spr  <- getObsIDX8r(Obs_ntaxa_spr[k],getZObs_r_new(sdobs_ntaxa,N_runs))
  ObsIDX8r_aut  <- getObsIDX8r(Obs_ntaxa_aut[k],getZObs_r_new(sdobs_ntaxa,N_runs))
  
  Obs_site1_ntaxa_spr <- ObsIDX8r_spr + Ubias8r_spr # rename "Obs_site1_ntaxa_spr" to ObsIDX8rb_spr
  Obs_site1_ntaxa_aut <- ObsIDX8r_aut + Ubias8r_aut # rename "Obs_site1_ntaxa_aut" to ObsIDX8rb_aut
  
  # Part 2 . Do the RefAdjExpected bias
  
  sdexp8_ntaxa <- 0.53 # For aspt we use a different valsue
  ExpIDX8r_ntaxa_spr <- data.frame(val = (Exp_ref_ntaxa[k,1]+ getZObs_r_new (sdexp8_ntaxa, N_runs)))
  ExpIDX8r_ntaxa_aut <- data.frame(val = (Exp_ref_ntaxa[k,2]+ getZObs_r_new (sdexp8_ntaxa, N_runs)))
  
  EQR_ntaxa_spr <- as.data.frame(Obs_site1_ntaxa_spr/ExpIDX8r_ntaxa_spr[,1])
  EQR_ntaxa_aut <- as.data.frame(Obs_site1_ntaxa_aut/ExpIDX8r_ntaxa_aut[,1] )
  
  # Part 1: for "Spring" - DO FOR NTAXA 
  
  #Find the averages of both spr and autum, declare a function to compute this
  #
  eqr_av_spr  <- getAvgEQR_SprAut (EQR_ntaxa_spr,EQR_ntaxa_aut ) # 
  #print(eqr_av_spr)
  
   
  # Classify these for each SITE using the EQR just for spring and autumn
  classArray_siteOne_spr_ntaxa <- getClassarray_ntaxa(EQR_ntaxa_spr)
  classArray_siteOne_aut_ntaxa <- getClassarray_ntaxa(EQR_ntaxa_aut)
  
  # define an array to hold probability of class for each site- how much of the site belongs to each classes, adds up to 100%
  
  probClass_spr <- matrix(0, ncol = 1, nrow = 5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for two seasons or ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc
  probClass_aut <- matrix(0, ncol = 1, nrow = 5)
  
  for(i in 1:5) {
    probClass_spr[i] <- 100*sum(classArray_siteOne_spr_ntaxa[classArray_siteOne_spr_ntaxa==i,]/i)/N_runs
    probClass_aut[i] <- 100*sum(classArray_siteOne_aut_ntaxa[classArray_siteOne_aut_ntaxa==i,]/i)/N_runs
  }
  
  probabilityClass <- getProbClassLabelFromEQR()
  a_ntaxa_spr <- t(probClass_spr) # spr, need a_ntaxa_spr
  colnames(a_ntaxa_spr) <- getProbClassLabelFromEQR()[,1]
  rownames(a_ntaxa_spr) <- c(paste0("TST-",k))
  
  #Find most probable class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(a_ntaxa_spr)
  a_ntaxa_spr <- cbind(a_ntaxa_spr, mostProb) # add the site to the dataframe
  SiteProbabilityclasses_spr_ntaxa<- rbind(SiteProbabilityclasses_spr_ntaxa,a_ntaxa_spr)
  #Add the averages of spr,aut
  EQRAverages_ntaxa_spr <- rbind(EQRAverages_ntaxa_spr, eqr_av_spr)
  
  # Part 2: for Autumn
  a_ntaxa_aut<- t(probClass_aut) # aut
  colnames(a_ntaxa_aut) <- getProbClassLabelFromEQR()[,1]
  rownames(a_ntaxa_aut) <- c(paste0("TST-",k))
  
  mostProb <- getMostProbableClass(a_ntaxa_aut)
  a_ntaxa_aut <- cbind(a_ntaxa_aut, mostProb)   
  SiteProbabilityclasses_aut_ntaxa<- rbind(SiteProbabilityclasses_aut_ntaxa,a_ntaxa_aut)
  #Add the averages of spr,aut
  #EQRAverages_ntaxa_aut <- rbind(EQRAverages_ntaxa_aut, eqr_av_aut)
  
  # Part 3:: Do combined spr, aut processing
  #First find the row averages of all the 10,000 simulations
  rowAverage_spr_aut  <- data.frame(rowMeans(cbind(EQR_ntaxa_spr, EQR_ntaxa_aut)))
  # Classify these for each SITE using the EQR just for spring
  classArray_siteOne_combined_spr <- getClassarray_ntaxa(rowAverage_spr_aut)
  #Define an array to hold probability of class
  probClass_spr_aut_comb <- matrix(0, ncol = 1, nrow = 5)
  # Process probabilities
  for(i in 1:5) {
      probClass_spr_aut_comb[i] <- 100*sum(classArray_siteOne_combined_spr[classArray_siteOne_combined_spr==i,]/i)/N_runs
  }
  
  a_ntaxa_spr_aut <- t(probClass_spr_aut_comb) # spr
  colnames(a_ntaxa_spr_aut) <- getProbClassLabelFromEQR()[,1] # Rename the columns to H G M P B
  rownames(a_ntaxa_spr_aut) <- c(paste0("TST-",k))
  #Find most probable class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(a_ntaxa_spr_aut)
  a_ntaxa_spr_aut <- cbind(a_ntaxa_spr_aut, mostProb)   
  SiteProbabilityclasses_spr_aut_comb_ntaxa<- rbind(SiteProbabilityclasses_spr_aut_comb_ntaxa,a_ntaxa_spr_aut)
  
  # **** Workout FOR ASPT STARTS HERE 
  
  ## RALPH 
  u_9a  <- 4.35 
  u_9b <- 0.271 
  u_9c <- 2.5

  #### RALPH 
  Ubias9r_spr <- getUbias9r_new (u_9a, u_9b, u_9c,Obs_aspt_spr[k], N_runs, Ubias8r_spr)
  Ubias9r_aut <- getUbias9r_new (u_9a, u_9b, u_9c,Obs_aspt_aut[k], N_runs, Ubias8r_aut)

  Ubias7r_spr <- Ubias8r_spr*Ubias9r_spr
  Ubias7r_aut <- Ubias8r_aut*Ubias9r_aut
  
  ObsIDX9r_spr  <- getObsIDX9r (Obs_aspt_spr[k],getZObs_r_new(sdobs_aspt,N_runs)) 
  ObsIDX9r_aut  <- getObsIDX9r(Obs_aspt_aut[k],getZObs_r_new(sdobs_aspt,N_runs))
  
   
  ObsIDX7r_spr <-  ObsIDX8r_spr* ObsIDX9r_spr
  ObsIDX7r_aut <-  ObsIDX8r_aut* ObsIDX9r_aut

  ObsIDX7rb_spr <- ObsIDX7r_spr+Ubias7r_spr
  ObsIDX7rb_aut <- ObsIDX7r_aut+Ubias7r_aut
   
  ObsIDX8rb_spr <- ObsIDX8r_spr+Ubias8r_spr
  ObsIDX8rb_aut <- ObsIDX8r_aut+Ubias8r_aut
      
   
  ObsIDX9rb_spr <- ObsIDX7rb_spr/ObsIDX8rb_spr
  ObsIDX9rb_aut <- ObsIDX7rb_aut/ObsIDX8rb_aut
  
  # Part 2 . Do the RefAdjExpected bias
  
  # Expected reference adjusted , as an array , ONE SITE, site 14
  
  sdexp9_aspt <- 0.081 # For aspt we use a different value, 0.081
  ExpIDX9r_aspt_spr <- data.frame(val = (Exp_ref_aspt[k,1]+ getZObs_r_new (sdexp9_aspt, N_runs)))
  ExpIDX9r_aspt_aut <- data.frame(val = (Exp_ref_aspt[k,2]+ getZObs_r_new (sdexp9_aspt, N_runs)))
  
  # Calculating simulated EQR
  EQR_aspt_spr <- as.data.frame(ObsIDX9rb_spr/ExpIDX9r_aspt_spr[,1])
  EQR_aspt_aut <- as.data.frame(ObsIDX9rb_aut/ExpIDX9r_aspt_aut[,1] )
  
  # Part 1: for "Spring"
    
  #Find the averages of both spr and autum, declare a function to compute this
  # 
  eqr_av_spr_aspt  <- getAvgEQR_SprAut (EQR_aspt_spr,EQR_aspt_aut ) # 
  #print(eqr_av_spr)
  
  #eqr_av_aut  <- getAvgEQR_SprAut (EQR_ntaxa_spr,EQR_ntaxa_aut )
  
  # Classify these for each SITE using the EQR just for spring
  classArray_siteOne_spr_aspt <- getClassarray_aspt(EQR_aspt_spr)
  classArray_siteOne_aut_aspt <- getClassarray_aspt(EQR_aspt_aut)

  # define an array to hold probability of class for each site- how much of the site belongs to each classes, adds up to 100%
    
  probClass_spr <- matrix(0, ncol = 1, nrow = 5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for two seasons or ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc
  probClass_aut <- matrix(0, ncol = 1, nrow = 5)
  
  for(i in 1:5) {
    probClass_spr[i] <- 100*sum(classArray_siteOne_spr_aspt[classArray_siteOne_spr_aspt==i,]/i)/N_runs
    probClass_aut[i] <- 100*sum(classArray_siteOne_aut_aspt[classArray_siteOne_aut_aspt==i,]/i)/N_runs
  }
    
  # Work out ASPT probability of classes
  #probabilityClass <- getProbClassLabelFromEQR()
  a_aspt_spr <- t(probClass_spr) # spr
  colnames(a_aspt_spr) <- getProbClassLabelFromEQR()[,1]
  rownames(a_aspt_spr) <- c(paste0("TST-",k))
  
  #Find most probable class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(a_aspt_spr)
  # add the site to the dataframe
  a_aspt_spr <- cbind(a_aspt_spr, mostProb)  
  
  SiteProbabilityclasses_spr_aspt<- rbind(SiteProbabilityclasses_spr_aspt,a_aspt_spr)
  #Add the averages of spr
  EQRAverages_aspt_spr <- rbind(EQRAverages_aspt_spr, eqr_av_spr_aspt)
  
  # Part 2: for ASPT Autumn
  a_aspt_aut <- t(probClass_aut) # aut
  colnames(a_aspt_aut) <- getProbClassLabelFromEQR()[,1]
  rownames(a_aspt_aut) <- c(paste0("TST-",k))
  mostProb <- getMostProbableClass(a_aspt_aut)
  a_aspt_aut <- cbind(a_aspt_aut, mostProb)   
  SiteProbabilityclasses_aut_aspt<- rbind(SiteProbabilityclasses_aut_aspt,a_aspt_aut)
  #Add the averages of spr,aut
   
  # Part 3:: start the combined spr_aut processing
  #First find the row averages of all the 10,000 simulations
  rowAverage_spr_aut  <- data.frame(rowMeans(cbind(EQR_aspt_spr, EQR_aspt_aut)))
  # Classify these for each SITE using the EQR just for spring
  classArray_siteOne_combined_spr_aspt <- getClassarray_aspt(rowAverage_spr_aut)
  #Define an array to hold probability of class
  probClass_spr_aut_comb <- matrix(0, ncol = 1, nrow = 5)
  # Process probabilities
  
  for(i in 1:5) {
      probClass_spr_aut_comb[i] <- 100*sum(classArray_siteOne_combined_spr_aspt[classArray_siteOne_combined_spr_aspt==i,]/i)/N_runs
  }
  
  a_aspt_spr_aut <- t(probClass_spr_aut_comb) # spr
  colnames(a_aspt_spr_aut) <- getProbClassLabelFromEQR()[,1] # Rename the columns to H G M P B
  rownames(a_aspt_spr_aut) <- as.character(Allpredictions[k,"SITE"]) # c(paste0("TST-",k))
  #Find most probable class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(a_aspt_spr_aut)
  a_aspt_spr_aut <- cbind(a_aspt_spr_aut, mostProb)   
  SiteProbabilityclasses_spr_aut_comb_aspt<- rbind(SiteProbabilityclasses_spr_aut_comb_aspt,a_aspt_spr_aut)
     
  ########  Calculate the MINTA -spring case  worse class = 1 i.e. min of class from NTAXA and ASPT ######
  matrix_ntaxa_spr <- as.matrix(classArray_siteOne_spr_ntaxa)
  matrix_aspt_spr <- as.matrix(classArray_siteOne_spr_aspt)
  #minta_ntaxa_aspt_spr <- getMINTA_ntaxa_aspt (matrix_ntaxa_spr, matrix_aspt_spr)
  
  minta_ntaxa_aspt_spr <- getMINTA_ntaxa_aspt (as.matrix(classArray_siteOne_spr_ntaxa), as.matrix(classArray_siteOne_spr_aspt))
  # Now calculate proportion of each class H to B for MINTA  
  minta_probClass_spr <- matrix(0, ncol = 1, nrow = 5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for two seasons or ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc
   
  for(i in 1:5) {
      minta_probClass_spr[i] <- 100*sum(minta_ntaxa_aspt_spr[minta_ntaxa_aspt_spr==i,]/i)/N_runs
  }
    
  # probabilityClass <- getProbClassLabelFromEQR()
  aa <- t(minta_probClass_spr) # spr
  colnames(aa) <- getProbClassLabelFromEQR()[,1]
  rownames(aa) <- as.character(Allpredictions[k,"SITE"]) #c(paste0("TST-",k))
  # Find most probable MINTA class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(aa)
  aa <- cbind(aa, mostProb)   
  # Now bind the MINTA proportion to the dataframe
  SiteMINTA_whpt_spr <- rbind(SiteMINTA_whpt_spr, aa)
    
  # Do the MINTA aut case 
  
  minta_ntaxa_aspt_aut <- getMINTA_ntaxa_aspt (as.matrix(classArray_siteOne_aut_ntaxa),  as.matrix(classArray_siteOne_aut_aspt))
  minta_probClass_aut <- matrix(0, ncol = 1, nrow = 5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for two seasons or ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc
   
  for(i in 1:5) {
      minta_probClass_aut[i] <- 100*sum(minta_ntaxa_aspt_aut[minta_ntaxa_aspt_aut==i,]/i)/N_runs
  }
    
  # probabilityClass <- getProbClassLabelFromEQR()
  aa <- t(minta_probClass_aut) # spr
  colnames(aa) <- getProbClassLabelFromEQR()[,1]
  rownames(aa) <- as.character(Allpredictions[k,"SITE"]) #c(paste0("TST-",k))
  #Find most probable MINTA class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(aa)
  aa <- cbind(aa, mostProb)   
  # Now bind the MINTA proportion to the dataframe
  SiteMINTA_whpt_aut <- rbind(SiteMINTA_whpt_aut, aa)

  # Do the MINTA spr_aut case 
  minta_ntaxa_aspt_spr_aut <- getMINTA_ntaxa_aspt (as.matrix(classArray_siteOne_combined_spr),  as.matrix(classArray_siteOne_combined_spr_aspt))
  minta_probClass_spr_aut <- matrix(0, ncol = 1, nrow = 5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for two seasons or ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc
   
  for(i in 1:5) {
      minta_probClass_spr_aut[i] <- 100*sum(minta_ntaxa_aspt_spr_aut[minta_ntaxa_aspt_spr_aut==i,]/i)/N_runs
  }
    
  # probabilityClass <- getProbClassLabelFromEQR()
  aa <- t(minta_probClass_spr_aut) # spr
  colnames(aa) <- getProbClassLabelFromEQR()[,1]
  rownames(aa) <- as.character(Allpredictions[k,"SITE"]) #c(paste0("TST-",k))
  #Find most probable MINTA class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(aa)
  aa <- cbind(aa, mostProb)   
  # Now bind the MINTA proportion to the dataframe
  SiteMINTA_whpt_spr_aut <- rbind(SiteMINTA_whpt_spr_aut, aa)
  ##### MINTA ENDS HERE  #############
  
}# END of FOR LOOP

# **** FOR NTAXA outputs **********

# Find the averages of these across seasons aver#(spr, aut)
colnames(EQRAverages_ntaxa_spr) <- c(paste0("NTAXA_",colnames(EQRAverages_ntaxa_spr)))
whpt_ntaxa_spr_aut_averages <- data.frame(NTAXA_aver_spr_aut=rowMeans(EQRAverages_ntaxa_spr))
#Change row names
rownames(whpt_ntaxa_spr_aut_averages) <- Allpredictions[,"SITE"]

# Rename column names so they dont conflict
colnames(SiteProbabilityclasses_spr_ntaxa) <- paste0(colnames(SiteProbabilityclasses_spr_ntaxa), "_NTAXA_spr")
colnames(SiteProbabilityclasses_aut_ntaxa) <- paste0(colnames(SiteProbabilityclasses_aut_ntaxa), "_NTAXA_aut")
colnames(SiteProbabilityclasses_spr_aut_comb_ntaxa) <- paste0(colnames(SiteProbabilityclasses_spr_aut_comb_ntaxa), "_NTAXA_spr_aut")

# Get ntaxa spr average
averages_spr_ntaxa <- cbind(EQRAverages_ntaxa_spr[1],SiteProbabilityclasses_spr_ntaxa) # 

#Get ntaxa aut
averages_aut_ntaxa <- cbind(EQRAverages_ntaxa_spr[2],SiteProbabilityclasses_aut_ntaxa) # 
#Change row names
rownames(averages_aut_ntaxa) <- Allpredictions[,"SITE"]
all_spr_aut_ntaxa_averages <- cbind(averages_spr_ntaxa,averages_aut_ntaxa)

allProbClasses_ave_ntaxa <- cbind(all_spr_aut_ntaxa_averages,SiteProbabilityclasses_spr_aut_comb_ntaxa)
allResults <- cbind(allProbClasses_ave_ntaxa,whpt_ntaxa_spr_aut_averages)
allResults <- cbind(year_waterBody,allResults)

path <- "C:/DEFRA/Phase2/RICT-GB-SingleYearSprAutOnly_RSTUDIO_codes/Results"

# writeToFile(SiteProbabilityclasses_spr, path, "/SiteProbabilityclasses_spr.csv")
writeToFile(EQRAverages_ntaxa_spr, path, "/EQRAverages_ntaxa_spr_aut.csv")  
writeToFile(allResults, path, "/whpt_ntaxa_allResults.csv") 
all_minta <- cbind(year_waterBody,SiteMINTA_whpt_spr )
all_minta <- cbind(all_minta, SiteMINTA_whpt_aut)
allntaxa_minta <- cbind(all_minta, SiteMINTA_whpt_spr_aut)
writeToFile(all_minta, path,"/ALL_whpt_MINTA.csv")

# ****** FOr ASPT outputs ********

# Find the averages of these across seasons aver#(spr, aut)
colnames(EQRAverages_aspt_spr) <- c(paste0("ASPT_",colnames(EQRAverages_aspt_spr)))
whpt_aspt_spr_aut_averages_aspt <- data.frame(ASPT_aver_spr_aut=rowMeans(EQRAverages_aspt_spr))

# Rename column names so they dont conflict
colnames(SiteProbabilityclasses_spr_aspt) <- paste0(colnames(SiteProbabilityclasses_spr_aspt), "_ASPT_spr")
colnames(SiteProbabilityclasses_aut_aspt) <- paste0(colnames(SiteProbabilityclasses_aut_aspt), "_ASPT_aut")
colnames(SiteProbabilityclasses_spr_aut_comb_aspt) <- paste0(colnames(SiteProbabilityclasses_spr_aut_comb_aspt), "_ASPT_spr_aut")

averages_spr_aspt <- cbind(EQRAverages_aspt_spr[1],SiteProbabilityclasses_spr_aspt)  
averages_aut_aspt <- cbind(EQRAverages_aspt_spr[2],SiteProbabilityclasses_aut_aspt) 
all_spr_aut_aspt_averages <- cbind(averages_spr_aspt,averages_aut_aspt)
  
allProbClasses_ave_aspt <- cbind(all_spr_aut_aspt_averages,SiteProbabilityclasses_spr_aut_comb_aspt)
allResults_aspt <- cbind(allProbClasses_ave_aspt,whpt_aspt_spr_aut_averages_aspt)
rownames(allResults_aspt) <- Allpredictions[,"SITE"]

# writeToFile(SiteProbabilityclasses_spr, path, "/SiteProbabilityclasses_spr.csv")
EQRAverages_aspt_spr <- cbind(year_waterBody,EQRAverages_aspt_spr)
rownames(EQRAverages_aspt_spr) <- Allpredictions[,"SITE"]
writeToFile(EQRAverages_aspt_spr, path, "/EQRAverages_ntaxa_spr_aut.csv")  
# Add waterbody, and YEAR
allResults_all <- cbind(year_waterBody, allResults_aspt)
rownames(EQRAverages_aspt_spr) <- Allpredictions[,"SITE"]

writeToFile(allResults_all, path, "/whpt_aspt_allResults.csv") 
all_spr_aut <- cbind(allResults, allResults_aspt)
all <- cbind(all_spr_aut,all_minta)
rownames(all) <- Allpredictions[,"SITE"]
all <- cbind(Allpredictions[,"SITE"], all)
names(all) <- c("SITE",names(all)[-1])
writeToFile(all, path, "/all_GB_SingYear_aut_spr.csv") 
 
end_time <- Sys.time()
print("Time = ")
print(end_time - start_time)
```
