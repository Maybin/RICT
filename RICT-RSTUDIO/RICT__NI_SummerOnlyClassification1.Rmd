---
title : "RICT NI Model Single Season - Summer single Year Classification Version 1"
output: html_document
Author: Dr K Maybin. Muyeba
Date  : 19th November 2019
Place : Richard Fairclough House, Knutsford Rd, Warrington WA4 1HT 
---

#This Script reads all prediction indices for classification 
# We only use column "SITE", p1-p43, SuitCode", "SuitText", "BelongsTo_endGrp", "TL2_WHPT_NTAXA_AbW_DistFam_spr",
# "TL2_WHPT_ASPT_AbW_DistFam_spr"  "TL2_WHPT_NTAXA_AbW_DistFam_aut" "TL2_WHPT_ASPT_AbW_DistFam_aut"

```{r}
library(dplyr)

# incluce all classification functions 
path <-  "C:/DEFRA/Phase2/RICT-NI-SingleYearSummerOnly_RSTUDIO_codes"
setwd(path)

source(paste0(path,'/datafiles/ClassificationfunctionsV2.R'))
  
set.seed (1234) #(2345)

# Input all predictions
Allpredictions <- read.csv(paste0(path,"/Results/FinalPredictions_NI_data.csv"))

# Input endgroup scores 1 to 5 , Site quality scores (Q1, Q2, Q3, Q4, Q5)
GB685_Ass_score <- read.csv(paste0(path,"/datafiles/EndGrp_AssessScoresNI.csv"), header = TRUE)

# Input Multiplicative Adjustment factors Aj, 1,..,5)
Aj <- as.matrix(read.csv(paste0(path,"/datafiles/adjustParams_ntaxa_aspt.csv"), header = TRUE))

# Remove the raw_data log inputs, including the counting column 1
Allpredictions <- Allpredictions[,-c(1,3:13)] 

# Choose all classification biological variables
namesBiological <- c("SPR_SEASON_ID", "SPR_TL2_WHPT_ASPT..ABW.DISTFAM.","SPR_TL2_WHPT_NTAXA..ABW.DISTFAM.", "SPR_NTAXA_BIAS", "SUM_SEASON_ID", "SUM_TL2_WHPT_ASPT..ABW.DISTFAM.","SUM_TL2_WHPT_NTAXA..ABW.DISTFAM.", "SUM_NTAXA_BIAS", "AUT_SEASON_ID", "AUT_TL2_WHPT_ASPT..ABW.DISTFAM.","AUT_TL2_WHPT_NTAXA..ABW.DISTFAM.","AUT_NTAXA_BIAS")
     
biologicalData <- Allpredictions[,  namesBiological] # c(56:67)] # change AZURE 

#Keep YEAR, WATERBODY
year_waterBody <- Allpredictions[,c("YEAR","WATERBODY")]
 
# Extract Ubias8 from Biological data # 
UBIAS_main <- biologicalData[,"SUM_NTAXA_BIAS"][1] # Put new AZURE. Use the default as 1.68,  "SPR_NTAXA_BIAS"][1]

 # Put the UBIAS_main default value of 1.68 if the user does not enter any value or entersa -9
if(is.na(UBIAS_main) | UBIAS_main==-9) { # For NI model, the default is ZERO
  UBIAS_main <- 1.68
}

# OBSERVED NTAXA
# OBSERVED NTAXA SUMMER
Obs_ntaxa_sum    <- biologicalData[,"SUM_TL2_WHPT_NTAXA..ABW.DISTFAM."] # change AZURE

          # Obs_ntaxa_spr    <- biologicalData[,"SPR_TL2_WHPT_NTAXA..ABW.DISTFAM."] # change AZURE
          # Obs_ntaxa_aut    <- biologicalData[,"AUT_TL2_WHPT_NTAXA..ABW.DISTFAM."] # change AZURE
# OBSERVED ASPT SUMMER
Obs_aspt_sum   <- biologicalData[,"SUM_TL2_WHPT_ASPT..ABW.DISTFAM."] # change AZURE

# OBSERVED ASPT
        # Obs_aspt_spr   <- biologicalData[,"SPR_TL2_WHPT_ASPT..ABW.DISTFAM."] # change AZURE
        # Obs_aspt_aut   <- biologicalData[,"AUT_TL2_WHPT_ASPT..ABW.DISTFAM."] # change AZURE

#Remove the "_CompFarm_" columns
Allpredictions <- select(Allpredictions, -matches("_CompFam_") ) # use the "-" with "match" from dplyr

# Also remove biological data, # Put AZURE 
Allpredictions <- Allpredictions[,!names(Allpredictions) %in% namesBiological  ]

#Store allProbabilities in one dataframe. Use p1,p2,... etc in case data column positions change in future

probNames <- c("p1","p2","p3","p4","p5","p6","p7","p8","p9","p10","p11")

allProbabilities <-Allpredictions[,probNames]

```

## Calculate AdjustedExpected from all probabilities, WE4.5 of WFD72C

```{r}
# Compute Qij
Qij <- computeScoreProportions(GB685_Ass_score[,-1]) # Remove the first Column

# Compute Rj = sum(Pi*Qij)
Rj <- as.matrix(getWeighted_proportion_Rj(allProbabilities, Qij))# We should havew five of these 

#Multiply Rj by Aj, note each row of Aj is for NTAXA, ASPT, so transpose to multiply by Rj
RjAj <- compute_RjAj(Rj, Aj)
One_over_RjAj <- 1/RjAj
# 
# Write a function that computes aspt, ntaxa adjusted (1 = "NTAXA", 2="ASPT") or select them by name as declared in the classification functions 
ntaxa_Adjusted <- select(Allpredictions, matches("_NTAXA_")) / RjAj[,"NTAXA"]
aspt_Adjusted  <- select(Allpredictions, matches("_ASPT_")) / RjAj[,"ASPT"] #Compute AdjExpected as E=Allpredictions/Sum(Rj*Aj)

Adjusted_Expected <- cbind(ntaxa_Adjusted, aspt_Adjusted)
Adjusted_Expected_new <- cbind(as.data.frame(Allpredictions[,1]), Adjusted_Expected) # Include site names from Allpredictions
writeToFile(Adjusted_Expected_new, path, "/Results/AdjExpectedValues_new_data.csv")

# NOTE: Use "Allpredictions" or "AdjustedExpected_new" dataframes for the next section of calculations
```


# Calculation of Exp_ref from "AdjustedExpected_new" values, divide by K ( = 1.0049 for NTAXA,  = 0.9921 for ASPT)

```{r}

# ******* FOR ASPT ************
Exp_ref_aspt  <- aspt_Adjusted/0.9921
 
Ubias8 <- UBIAS_main
# run simulations from here 
N_runs <- 10000 # 10000

# find the non-bias corrected  EQR = Obs/ExpRef
      #nonBiasCorrected_WHPT_aspt_spr <- Obs_aspt_spr/select(Exp_ref_aspt, matches("_spr"))
      #nonBiasCorrected_WHPT_aspt_aut <- Obs_aspt_aut/select(Exp_ref_aspt, matches("_aut"))
nonBiasCorrected_WHPT_aspt_sum   <- Obs_aspt_sum/select(Exp_ref_aspt, matches("_sum"))

# Now do the Obs_rb withONE SITE Obs_aspt_spr[1]
sdobs_aspt <- SDObs_One_year_new(0.269, 0.279, 1)
   
#SiteProbabilityclasses_spr_aspt <- data.frame() # Store site probabilities in a dataframe
#SiteProbabilityclasses_aut_aspt <- data.frame() # Store site probabilities in a dataframe
#SiteProbabilityclasses_spr_aut_comb_aspt <- data.frame()

# summer
SiteProbabilityclasses_sum_aspt <- data.frame() # Store site probabilities in a dataframe

#EQRAverages_aspt_spr <- data.frame() # Store average EQRs for spr in a dataframe
#EQRAverages_aspt_aut <- data.frame() # Store average EQRs for spr in a dataframe

#Summer
EQRAverages_aspt_sum <- data.frame() # Store average EQRs for spr in a dataframe


# ******** FOr NTAXA ***************
Exp_ref_ntaxa <- ntaxa_Adjusted/1.0049 # select(Adjusted_Expected_new, matches("_NTAXA_"))/1.0049
writeToFile(cbind(Exp_ref_ntaxa,Exp_ref_aspt), path, "/Results/Exp_ref_ntaxa_aspt.csv")

# find the non-bias corrected  EQR = Obs/ExpRef, from the raw inputs, not used but useful for output checking purposes only
# nonBiasCorrected_WHPT_ntaxa_spr <- Obs_ntaxa_spr/select(Exp_ref_ntaxa, matches("_spr"))
# nonBiasCorrected_WHPT_ntaxa_aut <- Obs_ntaxa_aut/select(Exp_ref_ntaxa, matches("_aut"))


# summer
nonBiasCorrected_WHPT_ntaxa_sum <- Obs_ntaxa_sum/select(Exp_ref_ntaxa, matches("_sum"))

# Now do the Obs_rb with ONE SITE Obs_ntaxa_spr[1]
sdobs_ntaxa <- SDObs_One_year_new(0.247, 0.211, 1)
 

            #SiteProbabilityclasses_spr_ntaxa <- data.frame() # Store site probabilities in a dataframe
            #SiteProbabilityclasses_aut_ntaxa <- data.frame() # Store site probabilities in a dataframe
            #SiteProbabilityclasses_spr_aut_comb_ntaxa <- data.frame()
# Summer
SiteProbabilityclasses_sum_ntaxa <- data.frame() # Store site probabilities in a dataframe



        #SiteMINTA_whpt_spr <- data.frame()
        #SiteMINTA_whpt_aut <- data.frame()
        #SiteMINTA_whpt_spr_aut <- data.frame()
# Summer
SiteMINTA_whpt_sum <- data.frame()
        
        #EQRAverages_ntaxa_spr <- data.frame() # Store average EQRs for spr in a dataframe
        #EQRAverages_ntaxa_aut <- data.frame() # Store average EQRs for spr in a dataframe
        
# Summer
EQRAverages_ntaxa_sum <- data.frame()  # Store average EQRs for spr in a datafram

        #Ubias8r_spr <-  getUbias8r_new (N_runs, Ubias8)
        #Ubias8r_aut <-  getUbias8r_new (N_runs, Ubias8)


# Summer
Ubias8r_sum <-  getUbias8r_new (N_runs, Ubias8)

#k<- 1
for (k in 1:nrow(Allpredictions)) {
    # LOOP all the sites from here   
    # Part 1. Adjust the Observed values
    # Loop starts from here with site = k, i.e. sqr (sqrt(Obs) + ZObs) + Ubias8r
  
  # Deal with NTAXA
                #ObsIDX8r_spr  <- getObsIDX8r(Obs_ntaxa_spr[k],getZObs_r_new(sdobs_ntaxa,N_runs))
                #ObsIDX8r_aut  <- getObsIDX8r(Obs_ntaxa_aut[k],getZObs_r_new(sdobs_ntaxa,N_runs))
                
                #Obs_site1_ntaxa_spr <- ObsIDX8r_spr + Ubias8r_spr # rename "Obs_site1_ntaxa_spr" to ObsIDX8rb_spr
                #Obs_site1_ntaxa_aut <- ObsIDX8r_aut + Ubias8r_aut # rename "Obs_site1_ntaxa_aut" to ObsIDX8rb_aut
                
  #Summer
  ObsIDX8r_sum  <- getObsIDX8r(Obs_ntaxa_sum[k],getZObs_r_new(sdobs_ntaxa,N_runs)) # Obs_ntaxa_spr[k] used instead of Obs_ntaxa_sum[k] ****** !!!!  
   
  #Summer
  Obs_site1_ntaxa_sum <- ObsIDX8r_sum + Ubias8r_sum # rename "Obs_site1_ntaxa_aut" to ObsIDX8rb_aut

  
  # Part 2 . Do the RefAdjExpected bias
  
  sdexp8_ntaxa <- 0.53 # For aspt we use a different valsue
  
            # ExpIDX8r_ntaxa_spr <- data.frame(val = (Exp_ref_ntaxa[k,1]+ getZObs_r_new (sdexp8_ntaxa, N_runs)))
            # ExpIDX8r_ntaxa_aut <- data.frame(val = (Exp_ref_ntaxa[k,2]+ getZObs_r_new (sdexp8_ntaxa, N_runs)))
  
            # EQR_ntaxa_spr <- as.data.frame(Obs_site1_ntaxa_spr/ExpIDX8r_ntaxa_spr[,1])
            # EQR_ntaxa_aut <- as.data.frame(Obs_site1_ntaxa_aut/ExpIDX8r_ntaxa_aut[,1] )
  
  # Summer
  ExpIDX8r_ntaxa_sum <- data.frame(val = (Exp_ref_ntaxa[k,1]+ getZObs_r_new (sdexp8_ntaxa, N_runs)))
    
  #Summer
  EQR_ntaxa_sum <- as.data.frame(Obs_site1_ntaxa_sum/ExpIDX8r_ntaxa_sum[,1] )
  
  # Part 1: for "Spring" - DO FOR NTAXA 
  #Find the averages of both spr and autum, declare a function to compute this
  #
            #eqr_av_spr  <- getAvgEQR_SprAut (EQR_ntaxa_spr,EQR_ntaxa_aut ) # 

  #Summer
  eqr_av_sum  <- getAvgEQR_SprAut (EQR_ntaxa_sum,EQR_ntaxa_sum ) # CHECK this mean function !!!!!
  
 #change to 1 value. Function "getAvgEQR_SprAut" is meant to compute for spr, aut
  a <-data.frame(eqr_av_sum=eqr_av_sum[,1])
  rownames(eqr_av_sum) <-  rownames(a) # Swap these 
  eqr_av_sum <- a
  
  # Classify these for each SITE using the EQR just for spring and autumn
           # classArray_siteOne_spr_ntaxa <- getClassarray_ntaxa(EQR_ntaxa_spr)
          #  classArray_siteOne_aut_ntaxa <- getClassarray_ntaxa(EQR_ntaxa_aut)
    
#Summer
classArray_siteOne_sum_ntaxa <- getClassarray_ntaxa(EQR_ntaxa_sum)
            
# define an array to hold probability of class for each site- how much of the site belongs to each classes, adds up to 100%
#summer
probClass_sum <- matrix(0, ncol = 1, nrow = 5)
  
 #probClass_spr <- matrix(0, ncol = 1, nrow = 5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for two seasons or ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc
  #probClass_aut <- matrix(0, ncol = 1, nrow = 5)
  
  for(i in 1:5) {
    probClass_sum[i] <- 100*sum(classArray_siteOne_sum_ntaxa[classArray_siteOne_sum_ntaxa==i,]/i)/N_runs
    #probClass_spr[i] <- 100*sum(classArray_siteOne_spr_ntaxa[classArray_siteOne_spr_ntaxa==i,]/i)/N_runs
    #probClass_aut[i] <- 100*sum(classArray_siteOne_aut_ntaxa[classArray_siteOne_aut_ntaxa==i,]/i)/N_runs
  }
  
          #probabilityClass <- getProbClassLabelFromEQR()
          #a_ntaxa_spr <- t(probClass_spr) # spr, need a_ntaxa_spr
          #colnames(a_ntaxa_spr) <- getProbClassLabelFromEQR()[,1]
          #rownames(a_ntaxa_spr) <- as.character(Allpredictions[k,"SITE"])  # c(paste0("TST-",k))
  # Summer 
  probabilityClass <- getProbClassLabelFromEQR()
  a_ntaxa_sum <- t(probClass_sum) # spr, need a_ntaxa_spr
  colnames(a_ntaxa_sum) <- getProbClassLabelFromEQR()[,1]
  rownames(a_ntaxa_sum) <- c(paste0("TST-",k))
          
  
  
  #Find most probable class, i.e the maximum, and add it to the site
            #mostProb <- getMostProbableClass(a_ntaxa_spr)
            #a_ntaxa_spr <- cbind(a_ntaxa_spr, mostProb) # add the site to the dataframe
            #SiteProbabilityclasses_spr_ntaxa<- rbind(SiteProbabilityclasses_spr_ntaxa,a_ntaxa_spr)
            ##Add the averages of spr,aut
            #EQRAverages_ntaxa_spr <- rbind(EQRAverages_ntaxa_spr, eqr_av_spr)
  
  #Summer
  mostProb <- getMostProbableClass(a_ntaxa_sum)
  a_ntaxa_sum <- cbind(a_ntaxa_sum, mostProb) # add the site to the dataframe
  SiteProbabilityclasses_sum_ntaxa<- rbind(SiteProbabilityclasses_sum_ntaxa,a_ntaxa_sum)
  
  #Add the averages of spr,aut
   
  #Summer NTAXA. Do similar one for ASPT
  EQRAverages_ntaxa_sum <- rbind(EQRAverages_ntaxa_sum, eqr_av_sum)
          
                      # Part 2: for Autumn
                      #a_ntaxa_aut<- t(probClass_aut) # aut
                      #colnames(a_ntaxa_aut) <- getProbClassLabelFromEQR()[,1]
                      #rownames(a_ntaxa_aut) <- as.character(Allpredictions[k,"SITE"]) #c(paste0("TST-",k))
                      
                      #mostProb <- getMostProbableClass(a_ntaxa_aut)
                      #a_ntaxa_aut <- cbind(a_ntaxa_aut, mostProb)   
                      #SiteProbabilityclasses_aut_ntaxa<- rbind(SiteProbabilityclasses_aut_ntaxa,a_ntaxa_aut)
                        
  # Part 3:: Do combined spr, aut processing
  #Summer: NO NEED
  #First find the row averages of all the 10,000 simulations
  rowAverage_sum_sum  <- data.frame(rowMeans(cbind(EQR_ntaxa_sum, EQR_ntaxa_sum)))

  
                  # Classify these for each SITE using the EQR just for spring
                  #  classArray_siteOne_combined_spr <- getClassarray_ntaxa(rowAverage_spr_aut)
                  ##  Define an array to hold probability of class
                  #  probClass_spr_aut_comb <- matrix(0, ncol = 1, nrow = 5)
                  ## Process probabilities
                  #  for(i in 1:5) {
                  #    probClass_spr_aut_comb[i] <- 100*sum(classArray_siteOne_combined_spr[classArray_siteOne_combined_spr==i,]/i)/N_runs
                  #  }
                  
                  #  a_ntaxa_spr_aut <- t(probClass_spr_aut_comb) # spr
                  #  colnames(a_ntaxa_spr_aut) <- getProbClassLabelFromEQR()[,1] # Rename the columns to H G M P B
                  #  rownames(a_ntaxa_spr_aut) <- as.character(Allpredictions[k,"SITE"]) # c(paste0("TST-",k))
                  ## Find most probable class, i.e the maximum, and add it to the site
                  # mostProb <- getMostProbableClass(a_ntaxa_spr_aut)
                  # a_ntaxa_spr_aut <- cbind(a_ntaxa_spr_aut, mostProb)   
                  # SiteProbabilityclasses_spr_aut_comb_ntaxa<- rbind(SiteProbabilityclasses_spr_aut_comb_ntaxa,a_ntaxa_spr_aut)
  
  # **** Workout FOR ASPT STARTS HERE 
  
  ## RALPH 
  u_9a  <- 4.35 
  u_9b <- 0.271 
  u_9c <- 2.5

  #### RALPH 
  #Summer
  Ubias9r_sum <- getUbias9r_new (u_9a, u_9b, u_9c,Obs_aspt_sum[k], N_runs, Ubias8r_sum)
  
          #Ubias9r_spr <- getUbias9r_new (u_9a, u_9b, u_9c,Obs_aspt_spr[k], N_runs, Ubias8r_spr)
          #Ubias9r_aut <- getUbias9r_new (u_9a, u_9b, u_9c,Obs_aspt_aut[k], N_runs, Ubias8r_aut)

   #Summer
  Ubias7r_sum <- Ubias8r_sum*Ubias9r_sum
      
          #Ubias7r_spr <- Ubias8r_spr*Ubias9r_spr
          #Ubias7r_aut <- Ubias8r_aut*Ubias9r_aut
  
  #summer 
  ObsIDX9r_sum  <- getObsIDX9r (Obs_aspt_sum[k],getZObs_r_new(sdobs_aspt,N_runs))
  
          #ObsIDX9r_spr  <- getObsIDX9r (Obs_aspt_spr[k],getZObs_r_new(sdobs_aspt,N_runs)) 
          #ObsIDX9r_aut  <- getObsIDX9r(Obs_aspt_aut[k],getZObs_r_new(sdobs_aspt,N_runs))
  
  #Summer
  ObsIDX7r_sum <-  ObsIDX8r_sum* ObsIDX9r_sum
    
          #ObsIDX7r_spr <-  ObsIDX8r_spr* ObsIDX9r_spr
          #ObsIDX7r_aut <-  ObsIDX8r_aut* ObsIDX9r_aut

 
  #Summer
  ObsIDX7rb_sum <- ObsIDX7r_sum+Ubias7r_sum

          #ObsIDX7rb_spr <- ObsIDX7r_spr+Ubias7r_spr
          #ObsIDX7rb_aut <- ObsIDX7r_aut+Ubias7r_aut
   
 # Summer
 ObsIDX8rb_sum <- ObsIDX8r_sum+Ubias8r_sum  
 
          #ObsIDX8rb_spr <- ObsIDX8r_spr+Ubias8r_spr
          #ObsIDX8rb_aut <- ObsIDX8r_aut+Ubias8r_aut
# summer
ObsIDX9rb_sum <- ObsIDX7rb_sum/ObsIDX8rb_sum
  
     
 # ObsIDX9rb_spr <- ObsIDX7rb_spr/ObsIDX8rb_spr
 # ObsIDX9rb_aut <- ObsIDX7rb_aut/ObsIDX8rb_aut
  
  # Part 2 . Do the RefAdjExpected bias
  # Expected reference adjusted , as an array , ONE SITE, site 14
  
  sdexp9_aspt <- 0.081 # For aspt we use a different value, 0.081
  
  #Summer
  ExpIDX9r_aspt_sum <- data.frame(val = (Exp_ref_aspt[k,1]+ getZObs_r_new (sdexp9_aspt, N_runs)))

            # ExpIDX9r_aspt_spr <- data.frame(val = (Exp_ref_aspt[k,1]+ getZObs_r_new (sdexp9_aspt, N_runs)))
            # ExpIDX9r_aspt_aut <- data.frame(val = (Exp_ref_aspt[k,2]+ getZObs_r_new (sdexp9_aspt, N_runs)))
            
  # Calculating simulated EQR
  
  # Summer
  EQR_aspt_sum <- as.data.frame(ObsIDX9rb_sum/ExpIDX9r_aspt_sum[,1])
        
            # EQR_aspt_spr <- as.data.frame(ObsIDX9rb_spr/ExpIDX9r_aspt_spr[,1])
            # EQR_aspt_aut <- as.data.frame(ObsIDX9rb_aut/ExpIDX9r_aspt_aut[,1] )
            
  # Part 1: for "Spring"
    
  #Find the averages of both spr and autum, declare a function to compute this
  # Summer      
  eqr_av_sum_aspt  <- getAvgEQR_SprAut (EQR_aspt_sum,EQR_aspt_sum ) #           
  #print(eqr_av_spr)
  
  #change to 1 value. Function "getAvgEQR_SprAut" is meant to compute for spr, aut
  a <-data.frame(eqr_av_sum_aspt=eqr_av_sum_aspt[,1])
   rownames(eqr_av_sum_aspt) <- rownames(a)
  eqr_av_sum_aspt <- a
  
  #eqr_av_aut  <- getAvgEQR_SprAut (EQR_ntaxa_spr,EQR_ntaxa_aut )
  
  # Classify these for each SITE using the EQR just for spring
            #classArray_siteOne_spr_aspt <- getClassarray_aspt(EQR_aspt_spr)
            #classArray_siteOne_aut_aspt <- getClassarray_aspt(EQR_aspt_aut)

  # Summer
classArray_siteOne_sum_aspt <- getClassarray_aspt(EQR_aspt_sum)

# define an array to hold probability of class for each site- how much of the site belongs to each classes, adds up to 100%
    
# probClass_spr <- matrix(0, ncol = 1, nrow = 5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc
# probClass_aut <- matrix(0, ncol = 1, nrow = 5)
  
# Summer
probClass_sum <- matrix(0,ncol = 1, nrow=5) # 5 is the number of classes- H, G, M, B, P, ncol=1 or 2 for two ntaxa_spr, ntaxa_aut, spr_aut_av_taxa, and spt etc

for(i in 1:5) {
    #probClass_spr[i] <- 100*sum(classArray_siteOne_spr_aspt[classArray_siteOne_spr_aspt==i,]/i)/N_runs
    #probClass_aut[i] <- 100*sum(classArray_siteOne_aut_aspt[classArray_siteOne_aut_aspt==i,]/i)/N_runs
    probClass_sum[i] <- 100*sum(classArray_siteOne_sum_aspt[classArray_siteOne_sum_aspt==i,]/i)/N_runs

}
    
# Work out ASPT probability of classes
# Summer
a_aspt_sum <- t(probClass_sum) # spr
colnames(a_aspt_sum) <- getProbClassLabelFromEQR()[,1]
rownames(a_aspt_sum) <- c(paste0("TST-",k))
     
# Summer   
#Find most probable class, i.e the maximum, and add it to the site
mostProb <- getMostProbableClass(a_aspt_sum)
# add the site to the dataframe
a_aspt_sum <- cbind(a_aspt_sum, mostProb)  
  

          # Prob class
# Summer
SiteProbabilityclasses_sum_aspt<- rbind(SiteProbabilityclasses_sum_aspt,a_aspt_sum)
#Add# the averages of sum for aspt
EQRAverages_aspt_sum <- rbind(EQRAverages_aspt_sum, eqr_av_sum_aspt)
        
  

########  Calculate the MINTA -spring case  worse class = 1 i.e. min of class from NTAXA and ASPT ######
# Summer
matrix_ntaxa_sum <- as.matrix(classArray_siteOne_sum_ntaxa)
matrix_aspt_sum <- as.matrix(classArray_siteOne_sum_aspt)
            #minta_ntaxa_aspt_spr <- getMINTA_ntaxa_aspt (matrix_ntaxa_spr, matrix_aspt_spr)
  
#Summer      
minta_ntaxa_aspt_sum <- getMINTA_ntaxa_aspt (as.matrix(classArray_siteOne_sum_ntaxa), 
                                                     as.matrix(classArray_siteOne_sum_aspt))      
        
# Now calculate proportion of each class H to B for MINTA  
# 
         #     minta_probClass_spr <- matrix(0, ncol = 1, nrow = 5) # 5 is the number 
              #of classes-H,G,M, B, P, ncol=1 or 2 for two seasons or ntaxa_spr,ntaxa_aut, spr_aut_av_taxa, and spt etc
  # Summer
  minta_probClass_sum <- matrix(0, ncol = 1, nrow = 5) 
  
  for(i in 1:5) {
      minta_probClass_sum[i] <- 100*sum(minta_ntaxa_aspt_sum[minta_ntaxa_aspt_sum==i,]/i)/N_runs
  }
    
  # probabilityClass <- getProbClassLabelFromEQR()
  aa <- t(minta_probClass_sum) # spr
  colnames(aa) <- getProbClassLabelFromEQR()[,1]
  rownames(aa) <- as.character(Allpredictions[k,"SITE"]) #c(paste0("TST-",k))
  # Find most probable MINTA class, i.e the maximum, and add it to the site
  mostProb <- getMostProbableClass(aa)
  aa <- cbind(aa, mostProb)   
  # Now bind the MINTA proportion to the dataframe
  SiteMINTA_whpt_sum <- rbind(SiteMINTA_whpt_sum, aa)   # ## STORE , APPEND THIS
     
  ##### MINTA ENDS HERE  #############
  
}# END of FOR LOOP



```

```{r}

# **** FOR NTAXA outputs **********

# Summer
colnames(EQRAverages_ntaxa_sum) <- c(paste0("NTAXA_",colnames(EQRAverages_ntaxa_sum)))

# Summer NO NEEd ,its the same as  "EQRAverages_ntaxa_sum"
 whpt_ntaxa_sum_sum_averages <- data.frame(NTAXA_aver_sum_sum=rowMeans(EQRAverages_ntaxa_sum))
    #Change row names, NO NO NO NO changed hehre 
 rownames(whpt_ntaxa_sum_sum_averages) <- Allpredictions[,"SITE"]
  
 
# Rename column names so they dont conflict

# Summer
colnames(SiteProbabilityclasses_sum_ntaxa) <- paste0(colnames(SiteProbabilityclasses_sum_ntaxa), "_NTAXA_sum")

# Summer
averages_sum_ntaxa <- cbind(EQRAverages_ntaxa_sum[1],SiteProbabilityclasses_sum_ntaxa) # 


## NEXT!! #Change row names
# Summer
#rownames(averages_sum_ntaxa) <- Allpredictions[,"SITE"] ## Allpredictions[,"SITE"] [1]
 

allProbClasses_ave_ntaxa <- averages_sum_ntaxa
#allResults <- cbind(year_waterBody,allProbClasses_ave_ntaxa)   ## cbind(year_waterBody[1,],allProbClasses_ave_ntaxa)
allResults <- allProbClasses_ave_ntaxa

# change column names for MINTA in SiteMINTA_whpt_sum
colnames(SiteMINTA_whpt_sum) <- paste0(colnames(SiteMINTA_whpt_sum),"_MINTA")

# writeToFile(SiteProbabilityclasses_spr, path, "/SiteProbabilityclasses_spr.csv")
writeToFile(EQRAverages_ntaxa_sum, path, "/Results/EQRAverages_ntaxa_sum.csv")  
writeToFile(allResults, path, "/Results/whpt_ntaxa_allResults.csv") 
all_minta <- cbind(year_waterBody, SiteMINTA_whpt_sum) ## cbind(year_waterBody[1,],SiteMINTA_whpt_sum )
#writeToFile(all_minta, path,"/Results/ALL_whpt_MINTA.csv")
allResults <- cbind(allResults,SiteMINTA_whpt_sum)
writeToFile(allResults ,path,"/Results/ALL_whpt_NTAXA_MINTA.csv")
## uphere deal with column names for all_minta,and rownames rom Allpredictions[,"SITE"]

# Start for aspt 
# ****** FOr ASPT outputs ********

# Find the averages of these across seasons aver#(spr, aut) 
#summer
#colnames(EQRAverages_aspt_sum) <- c(paste0("ASPT_",colnames(EQRAverages_aspt_sum)))
 
# Rename column names so they dont conflict
# Summer
colnames(SiteProbabilityclasses_sum_aspt) <- paste0(colnames(SiteProbabilityclasses_sum_aspt), "_ASPT_sum")
        
 
# Summer
averages_sum_aspt <- cbind(EQRAverages_aspt_sum,SiteProbabilityclasses_sum_aspt)  
      
      
#allProbClasses_ave_aspt <- cbind(all_spr_aut_aspt_averages,SiteProbabilityclasses_spr_aut_comb_aspt)
#allResults_aspt <- cbind(allProbClasses_ave_aspt,whpt_aspt_spr_aut_averages_aspt)
allResults_aspt <- averages_sum_aspt
rownames(allResults_aspt) <- NULL #Allpredictions[,"SITE"]    ##Allpredictions[,"SITE"][1]

# writeToFile(SiteProbabilityclasses_spr, path, "/SiteProbabilityclasses_spr.csv"), and 
# Add waterbody, and YEAR
allResults_aspt <- cbind(year_waterBody,averages_sum_aspt)
rownames(allResults_aspt) <- NULL
site <- data.frame(SITE = Allpredictions[,"SITE"])
#
#Add a column of SITES
allResults_aspt <- cbind(site, allResults_aspt)
writeToFile(allResults_aspt, path, "/Results/allResults_aspt.csv")  



#Write all Results
all_summer<- cbind(allResults_aspt,allResults)

writeToFile(all_summer, path, "/Results/whpt_aspt_ntaxa_allResults.csv") 



```



```{r}
### O   L   D    Code
# **** FOR NTAXA outputs **********
## Find the averages of these across seasons aver#(spr, aut)
#colnames(EQRAverages_ntaxa_spr) <- c(paste0("NTAXA_",colnames(EQRAverages_ntaxa_spr)))
#whpt_ntaxa_spr_aut_averages <- data.frame(NTAXA_aver_spr_aut=rowMeans(EQRAverages_ntaxa_spr))

#Rename column names so they dont conflict
#colnames(SiteProbabilityclasses_spr_ntaxa) <- paste0(colnames(SiteProbabilityclasses_spr_ntaxa), "_NTAXA_spr")
#colnames(SiteProbabilityclasses_aut_ntaxa) <- paste0(colnames(SiteProbabilityclasses_aut_ntaxa), "_NTAXA_aut")
#colnames(SiteProbabilityclasses_spr_aut_comb_ntaxa) <- paste0(colnames(SiteProbabilityclasses_spr_aut_comb_ntaxa), "_NTAXA_spr_aut")

##Get ntaxa spr average
#averages_spr_ntaxa <- cbind(EQRAverages_ntaxa_spr[1],SiteProbabilityclasses_spr_ntaxa) # 

##Get ntaxa aut
#averages_aut_ntaxa <- cbind(EQRAverages_ntaxa_spr[2],SiteProbabilityclasses_aut_ntaxa) # 
#all_spr_aut_ntaxa_averages <- cbind(averages_spr_ntaxa,averages_aut_ntaxa)

#allProbClasses_ave_ntaxa <- cbind(all_spr_aut_ntaxa_averages,SiteProbabilityclasses_spr_aut_comb_ntaxa)
#allResults <- cbind(allProbClasses_ave_ntaxa,whpt_ntaxa_spr_aut_averages)
#allResults <- cbind(year_waterBody,allResults)

#writeToFile(EQRAverages_ntaxa_spr, path, "/NI/EQRAverages_ntaxa_spr_aut.csv")  
#writeToFile(allResults, path, "/NI/whpt_ntaxa_allResults.csv") 
#all_minta <- cbind(year_waterBody,SiteMINTA_whpt_spr )
#all_minta <- cbind(all_minta, SiteMINTA_whpt_aut)
#allntaxa_minta <- cbind(all_minta, SiteMINTA_whpt_spr_aut)
#writeToFile(all_minta, path,"/NI/ALL_whpt_MINTA.csv")

## ****** FOr ASPT outputs ********

## Find the averages of these across seasons aver#(spr, aut)
#colnames(EQRAverages_aspt_spr) <- c(paste0("ASPT_",colnames(EQRAverages_aspt_spr)))
#whpt_aspt_spr_aut_averages_aspt <- data.frame(ASPT_aver_spr_aut=rowMeans(EQRAverages_aspt_spr))
#rownames(whpt_aspt_spr_aut_averages_aspt) <- Allpredictions[,"SITE"]

##Rename column names so they dont conflict
#colnames(SiteProbabilityclasses_spr_aspt) <- paste0(colnames(SiteProbabilityclasses_spr_aspt), "_ASPT_spr")
#colnames(SiteProbabilityclasses_aut_aspt) <- paste0(colnames(SiteProbabilityclasses_aut_aspt), "_ASPT_aut")
#colnames(SiteProbabilityclasses_spr_aut_comb_aspt) <- paste0(colnames(SiteProbabilityclasses_spr_aut_comb_aspt), "_ASPT_spr_aut")

#averages_spr_aspt <- cbind(EQRAverages_aspt_spr[1],SiteProbabilityclasses_spr_aspt) # 
#averages_aut_aspt <- cbind(EQRAverages_aspt_spr[2],SiteProbabilityclasses_aut_aspt) # 
#all_spr_aut_aspt_averages <- cbind(averages_spr_aspt,averages_aut_aspt)
  
#allProbClasses_ave_aspt <- cbind(all_spr_aut_aspt_averages,SiteProbabilityclasses_spr_aut_comb_aspt)
#rownames(allProbClasses_ave_aspt) <- Allpredictions[,"SITE"] 
#allResults_aspt <- cbind(allProbClasses_ave_aspt,whpt_aspt_spr_aut_averages_aspt)

#EQRAverages_aspt_spr <- cbind(year_waterBody,EQRAverages_aspt_spr)
#rownames(EQRAverages_aspt_spr) <- Allpredictions[,"SITE"]
#writeToFile(EQRAverages_aspt_spr, path, "/NI/EQRAverages_ntaxa_spr_aut.csv")  

##Add waterbody, and YEAR
#allResults <- cbind(year_waterBody, allResults_aspt)
#writeToFile(allResults_aspt, path, "/NI/whpt_aspt_allResults.csv") 


```

